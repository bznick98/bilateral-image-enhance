# general info
name: NeuralOps_FiveK_Init_ColorEWV_BilateralRenderer
notes: "Instance-Norm + model arch = ColorEWV bilateral renderer, using zb+wb generated init dataset"

# model
model: 
  name: colorewv_bilateral_neuralops
  n_in: 3
  n_out: 3
  encode_nf: 32
  return_vals: False
  lowres: [256, 256]
  luma_bins: 8
  spatial_bins: 32
  guide_pts: 8
  channel_multiplier: 1
  batch_norm: True # TODO: rename this to norm, actually uses Half-Instance-Norm
  iteratively_upsample: False
  load_path: null

# loss
loss:
  # weights for different loss components
  W_L2: 0                               # L2 loss (nn.MSELoss)
  W_L1: 1                               # L1 loss (nn.SmoothL1Loss)
  W_TV: 0                               # Total Variation Loss
  W_col: 0                              # Color Consistency Loss
  W_spa: 0                              # Spatial Consistency Loss
  W_exp: 0                              # Exposure Control Loss
  patch_size: 0                         # - patch size for exposure control loss
  E: 0                                  # - exposure level for exposure control loss
  W_cos: 0                              # Color Angle Loss


# dataset
dataset: EWVOps_Init                 # now supports [LOL, VELOL, SICE, FiveK]
data_dir: /home/ubuntu/capstone/Dataset/zb_NeuralOps_Init/
augment: True                           # augment training set if enabled
resize: null                            # input & target resize if specified
low_res: null                           # adding a low-res branch when retriving data, will return low_res, img, target
num_workers: 4                          # num_workers used in DataLoader

# train
lr: !!float 5e-5                        # learning rate
bs: 1                                   # batch size
beta1: 0.9                              # beta1 for Adam optimizer
beta2: 0.99                             # beta2 for Adam optimizer
weight_decay: !!float 1e-8              # weight decay
epochs: 400                             # number of training epochs 100,000 / 250
resume_from: null                       # resume pretrained model from this path
checkpoint_save_path: ./result/checkpoints/       # save checkpoint to {name}/ under this directory
visualization_save_path: ./result/visualization/  # save visualization to {name}/ under this directory

# eval
eval_model_path: ./result/checkpoints/NeuralOps_FiveKLite_Official_Pretrain/neurop_fivek_dark.pth  # checkpoint used for evaluation (test.py)

# misc
tensorboard: False                      # run "tensorboard --logdir runs/"
visualize_interval: 5                   # interval in terms of epochs to save visualization result, null == don't visualize
checkpoint_interval: 1                  # interval in terms of epochs to save model weights, null == don't save
device: cuda                            # choose from [cpu, cuda], null==use gpu if available if not cpu
profiling: True                         # if enabled, profile network performance on testing only
seed: 0                                 # for repeatability

